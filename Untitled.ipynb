{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ed0177",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import click\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from utils.config import Config\n",
    "from utils.visualization.plot_images_grid import plot_images_grid\n",
    "from DeepSAD import DeepSAD\n",
    "from datasets.main import load_dataset\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Settings\n",
    "################################################################################\n",
    "@click.command()\n",
    "@click.argument('dataset_name', type=click.Choice(['mnist', 'fmnist', 'cifar10', 'arrhythmia', 'cardio', 'satellite',\n",
    "                                                   'satimage-2', 'shuttle', 'thyroid']))\n",
    "@click.argument('net_name', type=click.Choice(['mnist_LeNet', 'fmnist_LeNet', 'cifar10_LeNet', 'arrhythmia_mlp',\n",
    "                                               'cardio_mlp', 'satellite_mlp', 'satimage-2_mlp', 'shuttle_mlp',\n",
    "                                               'thyroid_mlp']))\n",
    "@click.argument('xp_path', type=click.Path(exists=True))\n",
    "@click.argument('data_path', type=click.Path(exists=True))\n",
    "@click.option('--load_config', type=click.Path(exists=True), default=None,\n",
    "              help='Config JSON-file path (default: None).')\n",
    "@click.option('--load_model', type=click.Path(exists=True), default=None,\n",
    "              help='Model file path (default: None).')\n",
    "@click.option('--eta', type=float, default=1.0, help='Deep SAD hyperparameter eta (must be 0 < eta).')\n",
    "@click.option('--ratio_known_normal', type=float, default=0.0,\n",
    "              help='Ratio of known (labeled) normal training examples.')\n",
    "@click.option('--ratio_known_outlier', type=float, default=0.0,\n",
    "              help='Ratio of known (labeled) anomalous training examples.')\n",
    "@click.option('--ratio_pollution', type=float, default=0.0,\n",
    "              help='Pollution ratio of unlabeled training data with unknown (unlabeled) anomalies.')\n",
    "@click.option('--device', type=str, default='cuda', help='Computation device to use (\"cpu\", \"cuda\", \"cuda:2\", etc.).')\n",
    "@click.option('--seed', type=int, default=0, help='Set seed. If -1, use randomization.')\n",
    "@click.option('--optimizer_name', type=click.Choice(['adam']), default='adam',\n",
    "              help='Name of the optimizer to use for Deep SAD network training.')\n",
    "@click.option('--lr', type=float, default=0.001,\n",
    "              help='Initial learning rate for Deep SAD network training. Default=0.001')\n",
    "@click.option('--n_epochs', type=int, default=50, help='Number of epochs to train.')\n",
    "@click.option('--lr_milestone', type=int, default=0, multiple=True,\n",
    "              help='Lr scheduler milestones at which lr is multiplied by 0.1. Can be multiple and must be increasing.')\n",
    "@click.option('--batch_size', type=int, default=128, help='Batch size for mini-batch training.')\n",
    "@click.option('--weight_decay', type=float, default=1e-6,\n",
    "              help='Weight decay (L2 penalty) hyperparameter for Deep SAD objective.')\n",
    "@click.option('--pretrain', type=bool, default=True,\n",
    "              help='Pretrain neural network parameters via autoencoder.')\n",
    "@click.option('--ae_optimizer_name', type=click.Choice(['adam']), default='adam',\n",
    "              help='Name of the optimizer to use for autoencoder pretraining.')\n",
    "@click.option('--ae_lr', type=float, default=0.001,\n",
    "              help='Initial learning rate for autoencoder pretraining. Default=0.001')\n",
    "@click.option('--ae_n_epochs', type=int, default=100, help='Number of epochs to train autoencoder.')\n",
    "@click.option('--ae_lr_milestone', type=int, default=0, multiple=True,\n",
    "              help='Lr scheduler milestones at which lr is multiplied by 0.1. Can be multiple and must be increasing.')\n",
    "@click.option('--ae_batch_size', type=int, default=128, help='Batch size for mini-batch autoencoder training.')\n",
    "@click.option('--ae_weight_decay', type=float, default=1e-6,\n",
    "              help='Weight decay (L2 penalty) hyperparameter for autoencoder objective.')\n",
    "@click.option('--num_threads', type=int, default=0,\n",
    "              help='Number of threads used for parallelizing CPU operations. 0 means that all resources are used.')\n",
    "@click.option('--n_jobs_dataloader', type=int, default=0,\n",
    "              help='Number of workers for data loading. 0 means that the data will be loaded in the main process.')\n",
    "@click.option('--normal_class', type=int, default=0,\n",
    "              help='Specify the normal class of the dataset (all other classes are considered anomalous).')\n",
    "@click.option('--known_outlier_class', type=int, default=1,\n",
    "              help='Specify the known outlier class of the dataset for semi-supervised anomaly detection.')\n",
    "@click.option('--n_known_outlier_classes', type=int, default=0,\n",
    "              help='Number of known outlier classes.'\n",
    "                   'If 0, no anomalies are known.'\n",
    "                   'If 1, outlier class as specified in --known_outlier_class option.'\n",
    "                   'If > 1, the specified number of outlier classes will be sampled at random.')\n",
    "def main(dataset_name, net_name, xp_path, data_path, load_config, load_model, eta,\n",
    "         ratio_known_normal, ratio_known_outlier, ratio_pollution, device, seed,\n",
    "         optimizer_name, lr, n_epochs, lr_milestone, batch_size, weight_decay,\n",
    "         pretrain, ae_optimizer_name, ae_lr, ae_n_epochs, ae_lr_milestone, ae_batch_size, ae_weight_decay,\n",
    "         num_threads, n_jobs_dataloader, normal_class, known_outlier_class, n_known_outlier_classes):\n",
    "    \"\"\"\n",
    "    Deep SAD, a method for deep semi-supervised anomaly detection.\n",
    "\n",
    "    :arg DATASET_NAME: Name of the dataset to load.\n",
    "    :arg NET_NAME: Name of the neural network to use.\n",
    "    :arg XP_PATH: Export path for logging the experiment.\n",
    "    :arg DATA_PATH: Root path of data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get configuration\n",
    "    cfg = Config(locals().copy())\n",
    "\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    log_file = xp_path + '/log.txt'\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    # Print paths\n",
    "    logger.info('Log file is %s' % log_file)\n",
    "    logger.info('Data path is %s' % data_path)\n",
    "    logger.info('Export path is %s' % xp_path)\n",
    "\n",
    "    # Print experimental setup\n",
    "    logger.info('Dataset: %s' % dataset_name)\n",
    "    logger.info('Normal class: %d' % normal_class)\n",
    "    logger.info('Ratio of labeled normal train samples: %.2f' % ratio_known_normal)\n",
    "    logger.info('Ratio of labeled anomalous samples: %.2f' % ratio_known_outlier)\n",
    "    logger.info('Pollution ratio of unlabeled train data: %.2f' % ratio_pollution)\n",
    "    if n_known_outlier_classes == 1:\n",
    "        logger.info('Known anomaly class: %d' % known_outlier_class)\n",
    "    else:\n",
    "        logger.info('Number of known anomaly classes: %d' % n_known_outlier_classes)\n",
    "    logger.info('Network: %s' % net_name)\n",
    "\n",
    "    # If specified, load experiment config from JSON-file\n",
    "    if load_config:\n",
    "        cfg.load_config(import_json=load_config)\n",
    "        logger.info('Loaded configuration from %s.' % load_config)\n",
    "\n",
    "    # Print model configuration\n",
    "    logger.info('Eta-parameter: %.2f' % cfg.settings['eta'])\n",
    "\n",
    "    # Set seed\n",
    "    if cfg.settings['seed'] != -1:\n",
    "        random.seed(cfg.settings['seed'])\n",
    "        np.random.seed(cfg.settings['seed'])\n",
    "        torch.manual_seed(cfg.settings['seed'])\n",
    "        torch.cuda.manual_seed(cfg.settings['seed'])\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        logger.info('Set seed to %d.' % cfg.settings['seed'])\n",
    "\n",
    "    # Default device to 'cpu' if cuda is not available\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    # Set the number of threads used for parallelizing CPU operations\n",
    "    if num_threads > 0:\n",
    "        torch.set_num_threads(num_threads)\n",
    "    logger.info('Computation device: %s' % device)\n",
    "    logger.info('Number of threads: %d' % num_threads)\n",
    "    logger.info('Number of dataloader workers: %d' % n_jobs_dataloader)\n",
    "\n",
    "    # Load data\n",
    "    dataset = load_dataset(dataset_name, data_path, normal_class, known_outlier_class, n_known_outlier_classes,\n",
    "                           ratio_known_normal, ratio_known_outlier, ratio_pollution,\n",
    "                           random_state=np.random.RandomState(cfg.settings['seed']))\n",
    "    # Log random sample of known anomaly classes if more than 1 class\n",
    "    if n_known_outlier_classes > 1:\n",
    "        logger.info('Known anomaly classes: %s' % (dataset.known_outlier_classes,))\n",
    "\n",
    "    # Initialize DeepSAD model and set neural network phi\n",
    "    deepSAD = DeepSAD(cfg.settings['eta'])\n",
    "    deepSAD.set_network(net_name)\n",
    "\n",
    "    # If specified, load Deep SAD model (center c, network weights, and possibly autoencoder weights)\n",
    "    if load_model:\n",
    "        deepSAD.load_model(model_path=load_model, load_ae=True, map_location=device)\n",
    "        logger.info('Loading model from %s.' % load_model)\n",
    "\n",
    "    logger.info('Pretraining: %s' % pretrain)\n",
    "    if pretrain:\n",
    "        # Log pretraining details\n",
    "        logger.info('Pretraining optimizer: %s' % cfg.settings['ae_optimizer_name'])\n",
    "        logger.info('Pretraining learning rate: %g' % cfg.settings['ae_lr'])\n",
    "        logger.info('Pretraining epochs: %d' % cfg.settings['ae_n_epochs'])\n",
    "        logger.info('Pretraining learning rate scheduler milestones: %s' % (cfg.settings['ae_lr_milestone'],))\n",
    "        logger.info('Pretraining batch size: %d' % cfg.settings['ae_batch_size'])\n",
    "        logger.info('Pretraining weight decay: %g' % cfg.settings['ae_weight_decay'])\n",
    "\n",
    "        # Pretrain model on dataset (via autoencoder)\n",
    "        deepSAD.pretrain(dataset,\n",
    "                         optimizer_name=cfg.settings['ae_optimizer_name'],\n",
    "                         lr=cfg.settings['ae_lr'],\n",
    "                         n_epochs=cfg.settings['ae_n_epochs'],\n",
    "                         lr_milestones=cfg.settings['ae_lr_milestone'],\n",
    "                         batch_size=cfg.settings['ae_batch_size'],\n",
    "                         weight_decay=cfg.settings['ae_weight_decay'],\n",
    "                         device=device,\n",
    "                         n_jobs_dataloader=n_jobs_dataloader)\n",
    "\n",
    "        # Save pretraining results\n",
    "        deepSAD.save_ae_results(export_json=xp_path + '/ae_results.json')\n",
    "\n",
    "    # Log training details\n",
    "    logger.info('Training optimizer: %s' % cfg.settings['optimizer_name'])\n",
    "    logger.info('Training learning rate: %g' % cfg.settings['lr'])\n",
    "    logger.info('Training epochs: %d' % cfg.settings['n_epochs'])\n",
    "    logger.info('Training learning rate scheduler milestones: %s' % (cfg.settings['lr_milestone'],))\n",
    "    logger.info('Training batch size: %d' % cfg.settings['batch_size'])\n",
    "    logger.info('Training weight decay: %g' % cfg.settings['weight_decay'])\n",
    "\n",
    "    # Train model on dataset\n",
    "    deepSAD.train(dataset,\n",
    "                  optimizer_name=cfg.settings['optimizer_name'],\n",
    "                  lr=cfg.settings['lr'],\n",
    "                  n_epochs=cfg.settings['n_epochs'],\n",
    "                  lr_milestones=cfg.settings['lr_milestone'],\n",
    "                  batch_size=cfg.settings['batch_size'],\n",
    "                  weight_decay=cfg.settings['weight_decay'],\n",
    "                  device=device,\n",
    "                  n_jobs_dataloader=n_jobs_dataloader)\n",
    "\n",
    "    # Test model\n",
    "    deepSAD.test(dataset, device=device, n_jobs_dataloader=n_jobs_dataloader)\n",
    "\n",
    "    # Save results, model, and configuration\n",
    "    deepSAD.save_results(export_json=xp_path + '/results.json')\n",
    "    deepSAD.save_model(export_model=xp_path + '/model.tar')\n",
    "    cfg.save_config(export_json=xp_path + '/config.json')\n",
    "\n",
    "    # Plot most anomalous and most normal test samples\n",
    "    indices, labels, scores = zip(*deepSAD.results['test_scores'])\n",
    "    indices, labels, scores = np.array(indices), np.array(labels), np.array(scores)\n",
    "    idx_all_sorted = indices[np.argsort(scores)]  # from lowest to highest score\n",
    "    idx_normal_sorted = indices[labels == 0][np.argsort(scores[labels == 0])]  # from lowest to highest score\n",
    "\n",
    "    if dataset_name in ('mnist', 'fmnist', 'cifar10'):\n",
    "\n",
    "        if dataset_name in ('mnist', 'fmnist'):\n",
    "            X_all_low = dataset.test_set.data[idx_all_sorted[:32], ...].unsqueeze(1)\n",
    "            X_all_high = dataset.test_set.data[idx_all_sorted[-32:], ...].unsqueeze(1)\n",
    "            X_normal_low = dataset.test_set.data[idx_normal_sorted[:32], ...].unsqueeze(1)\n",
    "            X_normal_high = dataset.test_set.data[idx_normal_sorted[-32:], ...].unsqueeze(1)\n",
    "\n",
    "        if dataset_name == 'cifar10':\n",
    "            X_all_low = torch.tensor(np.transpose(dataset.test_set.data[idx_all_sorted[:32], ...], (0,3,1,2)))\n",
    "            X_all_high = torch.tensor(np.transpose(dataset.test_set.data[idx_all_sorted[-32:], ...], (0,3,1,2)))\n",
    "            X_normal_low = torch.tensor(np.transpose(dataset.test_set.data[idx_normal_sorted[:32], ...], (0,3,1,2)))\n",
    "            X_normal_high = torch.tensor(np.transpose(dataset.test_set.data[idx_normal_sorted[-32:], ...], (0,3,1,2)))\n",
    "\n",
    "        plot_images_grid(X_all_low, export_img=xp_path + '/all_low', padding=2)\n",
    "        plot_images_grid(X_all_high, export_img=xp_path + '/all_high', padding=2)\n",
    "        plot_images_grid(X_normal_low, export_img=xp_path + '/normals_low', padding=2)\n",
    "        plot_images_grid(X_normal_high, export_img=xp_path + '/normals_high', padding=2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf06c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58631a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
